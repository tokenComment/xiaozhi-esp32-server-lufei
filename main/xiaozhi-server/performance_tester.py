import time
import aiohttp
import asyncio
from tabulate import tabulate
from typing import Dict, List
from core.utils.llm import create_instance as create_llm_instance
from core.utils.tts import create_instance as create_tts_instance
from core.utils.util import read_config
import statistics
from config.settings import get_config_file
import inspect
import os
import logging

# è®¾ç½®å…¨å±€æ—¥å¿—çº§åˆ«ä¸ºWARNINGï¼ŒæŠ‘åˆ¶INFOçº§åˆ«æ—¥å¿—
logging.basicConfig(level=logging.WARNING)


class AsyncPerformanceTester:
    def __init__(self):
        # è¯»å–é…ç½®æ–‡ä»¶ï¼Œget_config_file å‡½æ•°åº”è¯¥ç”¨äºè·å–é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œread_config å‡½æ•°ç”¨äºè¯»å–é…ç½®æ–‡ä»¶å†…å®¹
        self.config = read_config(get_config_file())
        # ä»é…ç½®æ–‡ä»¶ä¸­è·å–æµ‹è¯•è¯­å¥åˆ—è¡¨ï¼Œå¦‚æœé…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰ç›¸åº”é…ç½®ï¼Œåˆ™ä½¿ç”¨é»˜è®¤çš„æµ‹è¯•è¯­å¥åˆ—è¡¨
        self.test_sentences = self.config.get("module_test", {}).get(
            "test_sentences",
            ["ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±", "What's the weather like today?",
             "è¯·ç”¨100å­—æ¦‚æ‹¬é‡å­è®¡ç®—çš„åŸºæœ¬åŸç†å’Œåº”ç”¨å‰æ™¯"]
        )
        # åˆå§‹åŒ–ç»“æœå­—å…¸ï¼Œç”¨äºå­˜å‚¨ä¸åŒæ¨¡å—ï¼ˆå¦‚å¤§è¯­è¨€æ¨¡å‹ã€æ–‡æœ¬è½¬è¯­éŸ³ï¼‰çš„æ€§èƒ½æµ‹è¯•ç»“æœä»¥åŠç»„åˆæµ‹è¯•ç»“æœ
        self.results = {
            "llm": {},
            "tts": {},
            "combinations": []
        }

    async def _check_ollama_service(self, base_url: str, model_name: str) -> bool:
        """å¼‚æ­¥æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€"""
        # åˆ›å»ºä¸€ä¸ªå¼‚æ­¥çš„ HTTP å®¢æˆ·ç«¯ä¼šè¯ï¼Œç”¨äºå‘é€ HTTP è¯·æ±‚
        async with aiohttp.ClientSession() as session:
            try:
                # æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨
                # å‘ Ollama æœåŠ¡çš„ /api/version ç«¯ç‚¹å‘é€ GET è¯·æ±‚
                async with session.get(f"{base_url}/api/version") as response:
                    # å¦‚æœå“åº”çŠ¶æ€ç ä¸æ˜¯ 200ï¼Œè¡¨ç¤ºæœåŠ¡ä¸å¯ç”¨ï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯å¹¶è¿”å› False
                    if response.status != 200:
                        print(f"ğŸš« OllamaæœåŠ¡æœªå¯åŠ¨æˆ–æ— æ³•è®¿é—®: {base_url}")
                        return False

                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
                # å‘ Ollama æœåŠ¡çš„ /api/tags ç«¯ç‚¹å‘é€ GET è¯·æ±‚ï¼Œè·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
                async with session.get(f"{base_url}/api/tags") as response:
                    # å¦‚æœå“åº”çŠ¶æ€ç ä¸º 200ï¼Œè¡¨ç¤ºæˆåŠŸè·å–æ¨¡å‹åˆ—è¡¨
                    if response.status == 200:
                        # å¼‚æ­¥è§£æå“åº”çš„ JSON æ•°æ®
                        data = await response.json()
                        # ä» JSON æ•°æ®ä¸­æå–æ¨¡å‹åˆ—è¡¨
                        models = data.get("models", [])
                        # æ£€æŸ¥æŒ‡å®šçš„æ¨¡å‹åç§°æ˜¯å¦åœ¨å¯ç”¨æ¨¡å‹åˆ—è¡¨ä¸­
                        if not any(model["name"] == model_name for model in models):
                            # å¦‚æœæ¨¡å‹ä¸å­˜åœ¨ï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯å¹¶è¿”å› False
                            print(f"ğŸš« Ollamaæ¨¡å‹ {model_name} æœªæ‰¾åˆ°ï¼Œè¯·å…ˆä½¿ç”¨ ollama pull {model_name} ä¸‹è½½")
                            return False
                    else:
                        # å¦‚æœæ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯å¹¶è¿”å› False
                        print(f"ğŸš« æ— æ³•è·å–Ollamaæ¨¡å‹åˆ—è¡¨")
                        return False
                # å¦‚æœæœåŠ¡å’Œæ¨¡å‹éƒ½æ­£å¸¸ï¼Œè¿”å› True
                return True
            except Exception as e:
                # å¦‚æœåœ¨æ£€æŸ¥è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸ï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯å¹¶è¿”å› False
                print(f"ğŸš« æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡: {str(e)}")
                return False

    async def _test_tts(self, tts_name: str, config: Dict) -> Dict:
        """å¼‚æ­¥æµ‹è¯•å•ä¸ªTTSæ€§èƒ½"""
        try:
            # è®¾ç½®æ—¥å¿—çº§åˆ«ï¼Œå°† core.providers.tts.base æ¨¡å—çš„æ—¥å¿—çº§åˆ«è®¾ç½®ä¸º WARNINGï¼Œå‡å°‘ä¸å¿…è¦çš„æ—¥å¿—è¾“å‡º
            logging.getLogger("core.providers.tts.base").setLevel(logging.WARNING)

            # å®šä¹‰å¯èƒ½åŒ…å«è®¿é—®ä»¤ç‰Œçš„å­—æ®µåˆ—è¡¨
            token_fields = ["access_token", "api_key", "token"]
            # æ£€æŸ¥é…ç½®ä¸­æ˜¯å¦å­˜åœ¨æœªé…ç½®çš„è®¿é—®ä»¤ç‰Œï¼Œå¦‚æœé…ç½®ä¸­åŒ…å« "ä½ çš„" æˆ– "placeholder" ç­‰å ä½ç¬¦ï¼Œè®¤ä¸ºæœªé…ç½®
            if any(field in config and any(x in config[field] for x in ["ä½ çš„", "placeholder"]) for field in
                token_fields):
                # è‹¥æœªé…ç½®ï¼Œæ‰“å°è·³è¿‡ä¿¡æ¯å¹¶è¿”å›é”™è¯¯ç»“æœ
                print(f"â­ï¸  TTS {tts_name} æœªé…ç½®access_token/api_keyï¼Œå·²è·³è¿‡")
                return {"name": tts_name, "type": "tts", "errors": 1}

            # ä»é…ç½®ä¸­è·å–æ¨¡å—ç±»å‹ï¼Œå¦‚æœæœªæŒ‡å®šåˆ™ä½¿ç”¨ TTS åç§°
            module_type = config.get('type', tts_name)
            # åˆ›å»º TTS å®ä¾‹ï¼Œè°ƒç”¨ create_tts_instance å‡½æ•°ï¼Œä¼ å…¥æ¨¡å—ç±»å‹ã€é…ç½®ä¿¡æ¯ï¼Œå¹¶è®¾ç½®åˆ é™¤éŸ³é¢‘æ–‡ä»¶
            tts = create_tts_instance(
                module_type,
                config,
                delete_audio_file=True
            )

            # æ‰“å°å¼€å§‹æµ‹è¯•çš„ä¿¡æ¯
            print(f"ğŸµ æµ‹è¯• TTS: {tts_name}")

            # ç”Ÿæˆä¸€ä¸ªä¸´æ—¶æ–‡ä»¶å
            tmp_file = tts.generate_filename()
            # è°ƒç”¨ TTS å®ä¾‹çš„ text_to_speak æ–¹æ³•ï¼Œå°† "è¿æ¥æµ‹è¯•" æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³å¹¶ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            await tts.text_to_speak("è¿æ¥æµ‹è¯•", tmp_file)

            # æ£€æŸ¥ä¸´æ—¶æ–‡ä»¶æ˜¯å¦ç”Ÿæˆï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè®¤ä¸ºè¿æ¥å¤±è´¥
            if not tmp_file or not os.path.exists(tmp_file):
                print(f"âŒ {tts_name} è¿æ¥å¤±è´¥")
                return {"name": tts_name, "type": "tts", "errors": 1}

            # åˆå§‹åŒ–æ€»è€—æ—¶ä¸º 0
            total_time = 0
            # ç¡®å®šæµ‹è¯•å¥å­çš„æ•°é‡ï¼Œå–å‰ä¸¤ä¸ªæµ‹è¯•å¥å­
            test_count = len(self.test_sentences[:2])

            # éå†å‰ä¸¤ä¸ªæµ‹è¯•å¥å­
            for i, sentence in enumerate(self.test_sentences[:2], 1):
                # è®°å½•å¼€å§‹æ—¶é—´
                start = time.time()
                # ç”Ÿæˆä¸€ä¸ªæ–°çš„ä¸´æ—¶æ–‡ä»¶å
                tmp_file = tts.generate_filename()
                # è°ƒç”¨ TTS å®ä¾‹çš„ text_to_speak æ–¹æ³•ï¼Œå°†æµ‹è¯•å¥å­è½¬æ¢ä¸ºè¯­éŸ³å¹¶ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                await tts.text_to_speak(sentence, tmp_file)
                # è®¡ç®—æœ¬æ¬¡è½¬æ¢çš„è€—æ—¶
                duration = time.time() - start
                # ç´¯åŠ æ€»è€—æ—¶
                total_time += duration

                # æ£€æŸ¥ä¸´æ—¶æ–‡ä»¶æ˜¯å¦ç”Ÿæˆï¼Œå¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œæ‰“å°æˆåŠŸä¿¡æ¯ï¼›å¦åˆ™æ‰“å°å¤±è´¥ä¿¡æ¯å¹¶è¿”å›é”™è¯¯ç»“æœ
                if tmp_file and os.path.exists(tmp_file):
                    print(f"âœ“ {tts_name} [{i}/{test_count}]")
                else:
                    print(f"âœ— {tts_name} [{i}/{test_count}]")
                    return {"name": tts_name, "type": "tts", "errors": 1}

            # æµ‹è¯•æˆåŠŸï¼Œè¿”å›åŒ…å« TTS åç§°ã€ç±»å‹ã€å¹³å‡è€—æ—¶å’Œé”™è¯¯æ•°é‡çš„ç»“æœå­—å…¸
            return {
                "name": tts_name,
                "type": "tts",
                "avg_time": total_time / test_count,
                "errors": 0
            }

        except Exception as e:
            # è‹¥æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸ï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯å¹¶è¿”å›é”™è¯¯ç»“æœ
            print(f"âš ï¸ {tts_name} æµ‹è¯•å¤±è´¥: {str(e)}")
            return {"name": tts_name, "type": "tts", "errors": 1}

    async def _test_llm(self, llm_name: str, config: Dict) -> Dict:
        """å¼‚æ­¥æµ‹è¯•å•ä¸ªLLMæ€§èƒ½"""
        try:
            # å¯¹äºOllamaï¼Œè·³è¿‡api_keyæ£€æŸ¥å¹¶è¿›è¡Œç‰¹æ®Šå¤„ç†
            if llm_name == "Ollama":
                # ä»é…ç½®ä¸­è·å–OllamaæœåŠ¡çš„åŸºç¡€URLï¼Œè‹¥æœªé…ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
                base_url = config.get('base_url', 'http://localhost:11434')
                # ä»é…ç½®ä¸­è·å–Ollamaä½¿ç”¨çš„æ¨¡å‹åç§°
                model_name = config.get('model_name')
                # è‹¥æœªé…ç½®æ¨¡å‹åç§°ï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯å¹¶è¿”å›åŒ…å«é”™è¯¯ä¿¡æ¯çš„å­—å…¸
                if not model_name:
                    print(f"ğŸš« Ollamaæœªé…ç½®model_name")
                    return {"name": llm_name, "type": "llm", "errors": 1}
                # è°ƒç”¨ _check_ollama_service æ–¹æ³•æ£€æŸ¥OllamaæœåŠ¡å’Œæ¨¡å‹æ˜¯å¦å¯ç”¨ï¼Œè‹¥ä¸å¯ç”¨åˆ™è¿”å›é”™è¯¯ä¿¡æ¯
                if not await self._check_ollama_service(base_url, model_name):
                    return {"name": llm_name, "type": "llm", "errors": 1}
            else:
                # å¯¹äºéOllamaçš„LLMï¼Œæ£€æŸ¥api_keyæ˜¯å¦é…ç½®ï¼Œè‹¥åŒ…å«å ä½ç¬¦åˆ™è·³è¿‡è¯¥LLMçš„æµ‹è¯•
                if "api_key" in config and any(x in config["api_key"] for x in ["ä½ çš„", "placeholder", "sk-xxx"]):
                    print(f"ğŸš« è·³è¿‡æœªé…ç½®çš„LLM: {llm_name}")
                    return {"name": llm_name, "type": "llm", "errors": 1}

            # è·å–å®é™…ç±»å‹ï¼ˆå…¼å®¹æ—§é…ç½®ï¼‰ï¼Œè‹¥é…ç½®ä¸­æœªæŒ‡å®š type åˆ™ä½¿ç”¨ llm_name
            module_type = config.get('type', llm_name)
            # æ ¹æ®æ¨¡å—ç±»å‹å’Œé…ç½®åˆ›å»ºLLMå®ä¾‹
            llm = create_llm_instance(module_type, config)

            # ç»Ÿä¸€ä½¿ç”¨UTF-8ç¼–ç ï¼Œå°†æµ‹è¯•å¥å­åˆ—è¡¨ä¸­çš„æ¯ä¸ªå¥å­è¿›è¡Œç¼–ç å’Œè§£ç æ“ä½œ
            test_sentences = [s.encode('utf-8').decode('utf-8') for s in self.test_sentences]

            # åˆ›å»ºæ‰€æœ‰å¥å­çš„æµ‹è¯•ä»»åŠ¡
            sentence_tasks = []
            # éå†æµ‹è¯•å¥å­åˆ—è¡¨ï¼Œä¸ºæ¯ä¸ªå¥å­åˆ›å»ºä¸€ä¸ªæµ‹è¯•ä»»åŠ¡
            for sentence in test_sentences:
                sentence_tasks.append(self._test_single_sentence(llm_name, llm, sentence))

            # å¹¶å‘æ‰§è¡Œæ‰€æœ‰å¥å­æµ‹è¯•ï¼Œä½¿ç”¨ asyncio.gather å¹¶å‘æ‰§è¡Œæ‰€æœ‰æµ‹è¯•ä»»åŠ¡å¹¶ç­‰å¾…ç»“æœ
            sentence_results = await asyncio.gather(*sentence_tasks)

            # å¤„ç†ç»“æœï¼Œè¿‡æ»¤æ‰ç»“æœåˆ—è¡¨ä¸­ä¸º None çš„é¡¹ï¼Œå¾—åˆ°æœ‰æ•ˆçš„ç»“æœåˆ—è¡¨
            valid_results = [r for r in sentence_results if r is not None]
            # è‹¥æœ‰æ•ˆç»“æœåˆ—è¡¨ä¸ºç©ºï¼Œè¯´æ˜å¯èƒ½é…ç½®é”™è¯¯ï¼Œæ‰“å°è­¦å‘Šä¿¡æ¯å¹¶è¿”å›é”™è¯¯ä¿¡æ¯
            if not valid_results:
                print(f"âš ï¸  {llm_name} æ— æœ‰æ•ˆæ•°æ®ï¼Œå¯èƒ½é…ç½®é”™è¯¯")
                return {"name": llm_name, "type": "llm", "errors": 1}

            # ä»æœ‰æ•ˆç»“æœåˆ—è¡¨ä¸­æå–æ¯ä¸ªæµ‹è¯•å¥å­çš„é¦–tokenå“åº”æ—¶é—´å’Œå®Œæ•´å“åº”æ—¶é—´
            first_token_times = [r["first_token_time"] for r in valid_results]
            response_times = [r["response_time"] for r in valid_results]

            # è¿‡æ»¤å¼‚å¸¸æ•°æ®ï¼Œè®¡ç®—å®Œæ•´å“åº”æ—¶é—´çš„å¹³å‡å€¼
            mean = statistics.mean(response_times)
            # è®¡ç®—å®Œæ•´å“åº”æ—¶é—´çš„æ ‡å‡†å·®ï¼Œè‹¥å“åº”æ—¶é—´åˆ—è¡¨é•¿åº¦å°äºç­‰äº1åˆ™æ ‡å‡†å·®ä¸º0
            stdev = statistics.stdev(response_times) if len(response_times) > 1 else 0
            # è¿‡æ»¤æ‰å¤§äºå¹³å‡å€¼åŠ 3å€æ ‡å‡†å·®çš„å“åº”æ—¶é—´ï¼Œå¾—åˆ°è¿‡æ»¤åçš„å“åº”æ—¶é—´åˆ—è¡¨
            filtered_times = [t for t in response_times if t <= mean + 3 * stdev]

            # è‹¥è¿‡æ»¤åçš„å“åº”æ—¶é—´åˆ—è¡¨é•¿åº¦å°äºæµ‹è¯•å¥å­æ•°é‡çš„ä¸€åŠï¼Œè¯´æ˜æœ‰æ•ˆæ•°æ®ä¸è¶³ï¼Œå¯èƒ½ç½‘ç»œä¸ç¨³å®šï¼Œæ‰“å°è­¦å‘Šä¿¡æ¯å¹¶è¿”å›é”™è¯¯ä¿¡æ¯
            if len(filtered_times) < len(test_sentences) * 0.5:
                print(f"âš ï¸  {llm_name} æœ‰æ•ˆæ•°æ®ä¸è¶³ï¼Œå¯èƒ½ç½‘ç»œä¸ç¨³å®š")
                return {"name": llm_name, "type": "llm", "errors": 1}

            # è‹¥æµ‹è¯•æ­£å¸¸å®Œæˆï¼Œè¿”å›åŒ…å«LLMåç§°ã€ç±»å‹ã€å¹³å‡å“åº”æ—¶é—´ã€å¹³å‡é¦–tokenå“åº”æ—¶é—´ã€é¦–tokenå“åº”æ—¶é—´æ ‡å‡†å·®ã€å®Œæ•´å“åº”æ—¶é—´æ ‡å‡†å·®å’Œé”™è¯¯æ•°é‡çš„å­—å…¸
            return {
                "name": llm_name,
                "type": "llm",
                "avg_response": sum(response_times) / len(response_times),
                "avg_first_token": sum(first_token_times) / len(first_token_times),
                "std_first_token": statistics.stdev(first_token_times) if len(first_token_times) > 1 else 0,
                "std_response": statistics.stdev(response_times) if len(response_times) > 1 else 0,
                "errors": 0
            }
        except Exception as e:
            # è‹¥æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸ï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯å¹¶è¿”å›åŒ…å«é”™è¯¯ä¿¡æ¯çš„å­—å…¸
            print(f"LLM {llm_name} æµ‹è¯•å¤±è´¥: {str(e)}")
            return {"name": llm_name, "type": "llm", "errors": 1}

    async def _test_single_sentence(self, llm_name: str, llm, sentence: str) -> Dict:
        """æµ‹è¯•å•ä¸ªå¥å­çš„æ€§èƒ½"""
        try:
            # æ‰“å°å¼€å§‹æµ‹è¯•çš„æç¤ºä¿¡æ¯ï¼Œæˆªå–å¥å­çš„å‰20ä¸ªå­—ç¬¦å±•ç¤º
            print(f"ğŸ“ {llm_name} å¼€å§‹æµ‹è¯•: {sentence[:20]}...")
            # è®°å½•æµ‹è¯•å¼€å§‹çš„æ—¶é—´
            sentence_start = time.time()
            # æ ‡è®°æ˜¯å¦æ¥æ”¶åˆ°é¦–ä¸ªæœ‰æ•ˆ tokenï¼Œåˆå§‹ä¸º False
            first_token_received = False
            # ç”¨äºå­˜å‚¨é¦–ä¸ªæœ‰æ•ˆ token å‡ºç°çš„æ—¶é—´ï¼Œåˆå§‹ä¸º None
            first_token_time = None

            async def process_response():
                """
            å¤„ç†LLMçš„å“åº”ï¼Œæ£€æµ‹é¦–ä¸ªæœ‰æ•ˆ token å¹¶è®°å½•æ—¶é—´
                """
                # å£°æ˜å¤–éƒ¨ä½œç”¨åŸŸçš„å˜é‡ï¼Œä»¥ä¾¿åœ¨å†…éƒ¨å‡½æ•°ä¸­ä¿®æ”¹
                nonlocal first_token_received, first_token_time
                # è°ƒç”¨ LLM çš„ response æ–¹æ³•è·å–å“åº”çš„æ¯ä¸ªæ•°æ®å—
                for chunk in llm.response("perf_test", [{"role": "user", "content": sentence}]):
                    # å¦‚æœè¿˜æœªæ¥æ”¶åˆ°é¦–ä¸ªæœ‰æ•ˆ token ä¸”å½“å‰æ•°æ®å—ä¸ä¸ºç©º
                    if not first_token_received and chunk.strip() != '':
                        # è®¡ç®—ä»æµ‹è¯•å¼€å§‹åˆ°é¦–ä¸ªæœ‰æ•ˆ token å‡ºç°çš„æ—¶é—´
                        first_token_time = time.time() - sentence_start
                        # æ ‡è®°å·²æ¥æ”¶åˆ°é¦–ä¸ªæœ‰æ•ˆ token
                        first_token_received = True
                        # æ‰“å°é¦–ä¸ªæœ‰æ•ˆ token å‡ºç°çš„æ—¶é—´
                        print(f"âœ“ {llm_name} é¦–ä¸ªToken: {first_token_time:.3f}s")
                    # ä»¥ç”Ÿæˆå™¨çš„æ–¹å¼è¿”å›æ¯ä¸ªæ•°æ®å—
                    yield chunk

            # ç”¨äºå­˜å‚¨ LLM å“åº”çš„æ‰€æœ‰æ•°æ®å—
            response_chunks = []
            # å¼‚æ­¥éå†å¤„ç†å“åº”çš„ç”Ÿæˆå™¨ï¼Œå°†æ¯ä¸ªæ•°æ®å—æ·»åŠ åˆ°åˆ—è¡¨ä¸­
            async for chunk in process_response():
                response_chunks.append(chunk)

            # è®¡ç®—ä»æµ‹è¯•å¼€å§‹åˆ°å®Œæ•´å“åº”ç»“æŸçš„æ€»æ—¶é—´
            response_time = time.time() - sentence_start
            # æ‰“å°å®Œæ•´å“åº”ç»“æŸçš„æ—¶é—´
            print(f"âœ“ {llm_name} å®Œæˆå“åº”: {response_time:.3f}s")

            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°é¦–ä¸ªæœ‰æ•ˆ tokenï¼Œå°†æ€»å“åº”æ—¶é—´ä½œä¸ºé¦–ä¸ªæœ‰æ•ˆ token çš„æ—¶é—´
            if first_token_time is None:
                first_token_time = response_time

            # è¿”å›åŒ…å« LLM åç§°ã€ç±»å‹ã€é¦–ä¸ªæœ‰æ•ˆ token æ—¶é—´å’Œå®Œæ•´å“åº”æ—¶é—´çš„å­—å…¸
            return {
                "name": llm_name,
                "type": "llm",
                "first_token_time": first_token_time,
                "response_time": response_time
            }
        except Exception as e:
            # å¦‚æœæµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸ï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯å¹¶è¿”å› None
            print(f"âš ï¸ {llm_name} å¥å­æµ‹è¯•å¤±è´¥: {str(e)}")
            return None

    def _generate_combinations(self):
        """ç”Ÿæˆæœ€ä½³ç»„åˆå»ºè®®"""
        # ç­›é€‰å‡ºæœ‰æ•ˆçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰
        # æ¡ä»¶ä¸ºè¯¥LLMæµ‹è¯•æ— é”™è¯¯ä¸”å¹³å‡é¦–ä¸ªtokenå“åº”æ—¶é—´å¤§äºç­‰äº0.05ç§’
        valid_llms = [
            k for k, v in self.results["llm"].items()
            if v["errors"] == 0 and v["avg_first_token"] >= 0.05
        ]
        # ç­›é€‰å‡ºæœ‰æ•ˆçš„æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å‹
        # æ¡ä»¶ä¸ºè¯¥TTSæµ‹è¯•æ— é”™è¯¯
        valid_tts = [k for k, v in self.results["tts"].items() if v["errors"] == 0]

        # æ‰¾å‡ºåŸºå‡†å€¼
        # è®¡ç®—æœ‰æ•ˆLLMä¸­å¹³å‡é¦–ä¸ªtokenå“åº”æ—¶é—´çš„æœ€å°å€¼ï¼Œè‹¥æ²¡æœ‰æœ‰æ•ˆLLMåˆ™è®¾ä¸º1
        min_first_token = min([self.results["llm"][llm]["avg_first_token"] for llm in valid_llms]) if valid_llms else 1
        # è®¡ç®—æœ‰æ•ˆTTSä¸­å¹³å‡å“åº”æ—¶é—´çš„æœ€å°å€¼ï¼Œè‹¥æ²¡æœ‰æœ‰æ•ˆTTSåˆ™è®¾ä¸º1
        min_tts_time = min([self.results["tts"][tts]["avg_time"] for tts in valid_tts]) if valid_tts else 1

        # éå†æ‰€æœ‰æœ‰æ•ˆçš„LLMå’ŒTTSè¿›è¡Œç»„åˆ
        for llm in valid_llms:
            for tts in valid_tts:
                # è®¡ç®—ç›¸å¯¹æ€§èƒ½åˆ†æ•°ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
                # LLMçš„ç›¸å¯¹æ€§èƒ½åˆ†æ•°ä¸ºè¯¥LLMçš„å¹³å‡é¦–ä¸ªtokenå“åº”æ—¶é—´é™¤ä»¥æœ€å°å¹³å‡é¦–ä¸ªtokenå“åº”æ—¶é—´
                llm_score = self.results["llm"][llm]["avg_first_token"] / min_first_token
                # TTSçš„ç›¸å¯¹æ€§èƒ½åˆ†æ•°ä¸ºè¯¥TTSçš„å¹³å‡å“åº”æ—¶é—´é™¤ä»¥æœ€å°å¹³å‡å“åº”æ—¶é—´
                tts_score = self.results["tts"][tts]["avg_time"] / min_tts_time

                # è®¡ç®—ç¨³å®šæ€§åˆ†æ•°ï¼ˆæ ‡å‡†å·®/å¹³å‡å€¼ï¼Œè¶Šå°è¶Šç¨³å®šï¼‰
                # LLMçš„ç¨³å®šæ€§åˆ†æ•°ä¸ºè¯¥LLMçš„é¦–ä¸ªtokenå“åº”æ—¶é—´çš„æ ‡å‡†å·®é™¤ä»¥å¹³å‡é¦–ä¸ªtokenå“åº”æ—¶é—´
                llm_stability = self.results["llm"][llm]["std_first_token"] / self.results["llm"][llm][
                    "avg_first_token"]

                # ç»¼åˆå¾—åˆ†ï¼ˆè€ƒè™‘æ€§èƒ½å’Œç¨³å®šæ€§ï¼‰
                # æ€§èƒ½æƒé‡0.7ï¼Œç¨³å®šæ€§æƒé‡0.3
                # è®¡ç®—LLMçš„æœ€ç»ˆå¾—åˆ†ï¼Œç»¼åˆè€ƒè™‘æ€§èƒ½å’Œç¨³å®šæ€§
                llm_final_score = llm_score * 0.7 + llm_stability * 0.3

                # æ€»åˆ† = LLMå¾—åˆ†(70%) + TTSå¾—åˆ†(30%)
                # è®¡ç®—LLMå’ŒTTSç»„åˆçš„æ€»å¾—åˆ†
                total_score = llm_final_score * 0.7 + tts_score * 0.3

                # å°†ç»„åˆä¿¡æ¯æ·»åŠ åˆ°ç»“æœçš„ç»„åˆåˆ—è¡¨ä¸­
                self.results["combinations"].append({
                    "llm": llm,
                    "tts": tts,
                    "score": total_score,
                    "details": {
                        "llm_first_token": self.results["llm"][llm]["avg_first_token"],
                        "llm_stability": llm_stability,
                        "tts_time": self.results["tts"][tts]["avg_time"]
                    }
                })

        # åˆ†æ•°è¶Šå°è¶Šå¥½
        # å¯¹ç»„åˆåˆ—è¡¨æŒ‰æ€»å¾—åˆ†è¿›è¡Œæ’åºï¼Œå¾—åˆ†å°çš„æ’åœ¨å‰é¢
        self.results["combinations"].sort(key=lambda x: x["score"])

    def _print_results(self):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        # åˆå§‹åŒ–ç”¨äºå­˜å‚¨LLMæ€§èƒ½æ•°æ®çš„è¡¨æ ¼
        llm_table = []
        # éå†LLMæµ‹è¯•ç»“æœ
        for name, data in self.results["llm"].items():
            # åªå¤„ç†æµ‹è¯•æ— é”™è¯¯çš„LLM
            if data["errors"] == 0:
                # è®¡ç®—LLMçš„ç¨³å®šæ€§ï¼Œå³é¦–å­—å“åº”æ—¶é—´çš„æ ‡å‡†å·®ä¸å¹³å‡é¦–å­—å“åº”æ—¶é—´çš„æ¯”å€¼
                stability = data["std_first_token"] / data["avg_first_token"]
                # å°†LLMçš„ç›¸å…³æ•°æ®æ·»åŠ åˆ°è¡¨æ ¼ä¸­ï¼ŒåŒ…æ‹¬æ¨¡å‹åç§°ã€é¦–å­—è€—æ—¶ã€æ€»è€—æ—¶å’Œç¨³å®šæ€§
                llm_table.append([
                    name,  # ä¸éœ€è¦å›ºå®šå®½åº¦ï¼Œè®©tabulateè‡ªå·±å¤„ç†å¯¹é½
                    f"{data['avg_first_token']:.3f}ç§’",
                    f"{data['avg_response']:.3f}ç§’",
                    f"{stability:.3f}"
                ])

        # å¦‚æœLLMè¡¨æ ¼ä¸­æœ‰æ•°æ®
        if llm_table:
            # æ‰“å°LLMæ€§èƒ½æ’è¡Œæ ‡é¢˜
            print("\nLLM æ€§èƒ½æ’è¡Œ:")
            # ä½¿ç”¨tabulateåº“å°†LLMè¡¨æ ¼æ•°æ®æ ¼å¼åŒ–ä¸ºè¡¨æ ¼å¹¶æ‰“å°
            print(tabulate(
                llm_table,
                headers=["æ¨¡å‹åç§°", "é¦–å­—è€—æ—¶", "æ€»è€—æ—¶", "ç¨³å®šæ€§"],
                tablefmt="github",
                colalign=("left", "right", "right", "right"),
                disable_numparse=True
            ))
        else:
            # å¦‚æœLLMè¡¨æ ¼ä¸­æ²¡æœ‰æ•°æ®ï¼Œæ‰“å°è­¦å‘Šä¿¡æ¯
            print("\nâš ï¸ æ²¡æœ‰å¯ç”¨çš„LLMæ¨¡å—è¿›è¡Œæµ‹è¯•ã€‚")

        # åˆå§‹åŒ–ç”¨äºå­˜å‚¨TTSæ€§èƒ½æ•°æ®çš„è¡¨æ ¼
        tts_table = []
        # éå†TTSæµ‹è¯•ç»“æœ
        for name, data in self.results["tts"].items():
            # åªå¤„ç†æµ‹è¯•æ— é”™è¯¯çš„TTS
            if data["errors"] == 0:
                # å°†TTSçš„ç›¸å…³æ•°æ®æ·»åŠ åˆ°è¡¨æ ¼ä¸­ï¼ŒåŒ…æ‹¬æ¨¡å‹åç§°å’Œåˆæˆè€—æ—¶
                tts_table.append([
                    name,  # ä¸éœ€è¦å›ºå®šå®½åº¦
                    f"{data['avg_time']:.3f}ç§’"
                ])

        # å¦‚æœTTSè¡¨æ ¼ä¸­æœ‰æ•°æ®
        if tts_table:
            # æ‰“å°TTSæ€§èƒ½æ’è¡Œæ ‡é¢˜
            print("\nTTS æ€§èƒ½æ’è¡Œ:")
            # ä½¿ç”¨tabulateåº“å°†TTSè¡¨æ ¼æ•°æ®æ ¼å¼åŒ–ä¸ºè¡¨æ ¼å¹¶æ‰“å°
            print(tabulate(
                tts_table,
                headers=["æ¨¡å‹åç§°", "åˆæˆè€—æ—¶"],
                tablefmt="github",
                colalign=("left", "right"),
                disable_numparse=True
            ))
        else:
            # å¦‚æœTTSè¡¨æ ¼ä¸­æ²¡æœ‰æ•°æ®ï¼Œæ‰“å°è­¦å‘Šä¿¡æ¯
            print("\nâš ï¸ æ²¡æœ‰å¯ç”¨çš„TTSæ¨¡å—è¿›è¡Œæµ‹è¯•ã€‚")

        # å¦‚æœæœ‰å¯ç”¨çš„æ¨¡å—ç»„åˆå»ºè®®
        if self.results["combinations"]:
            # æ‰“å°æ¨èé…ç½®ç»„åˆæ ‡é¢˜
            print("\næ¨èé…ç½®ç»„åˆ (å¾—åˆ†è¶Šå°è¶Šå¥½):")
            # åˆå§‹åŒ–ç”¨äºå­˜å‚¨ç»„åˆæ–¹æ¡ˆæ•°æ®çš„è¡¨æ ¼
            combo_table = []
            # éå†å‰5ä¸ªç»„åˆæ–¹æ¡ˆ
            for combo in self.results["combinations"][:5]:
                # å°†ç»„åˆæ–¹æ¡ˆçš„ç›¸å…³æ•°æ®æ·»åŠ åˆ°è¡¨æ ¼ä¸­ï¼ŒåŒ…æ‹¬ç»„åˆåç§°ã€ç»¼åˆå¾—åˆ†ã€LLMé¦–å­—è€—æ—¶ã€ç¨³å®šæ€§å’ŒTTSåˆæˆè€—æ—¶
                combo_table.append([
                    f"{combo['llm']} + {combo['tts']}",  # ä¸éœ€è¦å›ºå®šå®½åº¦
                    f"{combo['score']:.3f}",
                    f"{combo['details']['llm_first_token']:.3f}ç§’",
                    f"{combo['details']['llm_stability']:.3f}",
                    f"{combo['details']['tts_time']:.3f}ç§’"
                ])

            # ä½¿ç”¨tabulateåº“å°†ç»„åˆæ–¹æ¡ˆè¡¨æ ¼æ•°æ®æ ¼å¼åŒ–ä¸ºè¡¨æ ¼å¹¶æ‰“å°
            print(tabulate(
                combo_table,
                headers=["ç»„åˆæ–¹æ¡ˆ", "ç»¼åˆå¾—åˆ†", "LLMé¦–å­—è€—æ—¶", "ç¨³å®šæ€§", "TTSåˆæˆè€—æ—¶"],
                tablefmt="github",
                colalign=("left", "right", "right", "right", "right"),
                disable_numparse=True
            ))
        else:
            # å¦‚æœæ²¡æœ‰å¯ç”¨çš„æ¨¡å—ç»„åˆå»ºè®®ï¼Œæ‰“å°è­¦å‘Šä¿¡æ¯
            print("\nâš ï¸ æ²¡æœ‰å¯ç”¨çš„æ¨¡å—ç»„åˆå»ºè®®ã€‚")

    def _process_results(self, all_results):
        """å¤„ç†æµ‹è¯•ç»“æœ"""
        # éå†æ‰€æœ‰çš„æµ‹è¯•ç»“æœ
        for result in all_results:
            # æ£€æŸ¥å½“å‰æµ‹è¯•ç»“æœæ˜¯å¦æ²¡æœ‰é”™è¯¯
            if result["errors"] == 0:
                # åˆ¤æ–­å½“å‰æµ‹è¯•ç»“æœçš„ç±»å‹æ˜¯å¦ä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰
                if result["type"] == "llm":
                    # å¦‚æœæ˜¯LLMç±»å‹ï¼Œå°†è¯¥ç»“æœä»¥æ¨¡å‹åç§°ä¸ºé”®ï¼Œå­˜å‚¨åˆ° self.results å­—å…¸çš„ "llm" é”®å¯¹åº”çš„å­å­—å…¸ä¸­
                    self.results["llm"][result["name"]] = result
                else:
                    # å¦‚æœä¸æ˜¯LLMç±»å‹ï¼Œé»˜è®¤è®¤ä¸ºæ˜¯æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰ç±»å‹ï¼Œå°†è¯¥ç»“æœä»¥æ¨¡å‹åç§°ä¸ºé”®ï¼Œå­˜å‚¨åˆ° self.results å­—å…¸çš„ "tts" é”®å¯¹åº”çš„å­å­—å…¸ä¸­
                    self.results["tts"][result["name"]] = result

    async def run(self):
        """æ‰§è¡Œå…¨é‡å¼‚æ­¥æµ‹è¯•"""
        # æ‰“å°æç¤ºä¿¡æ¯ï¼Œè¡¨æ˜å¼€å§‹ç­›é€‰å¯ç”¨æ¨¡å—
        print("ğŸ” å¼€å§‹ç­›é€‰å¯ç”¨æ¨¡å—...")

        # åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨æ‰€æœ‰çš„æµ‹è¯•ä»»åŠ¡
        all_tasks = []

        # å¤„ç†LLMæµ‹è¯•ä»»åŠ¡
        # éå†é…ç½®ä¸­LLMéƒ¨åˆ†çš„æ‰€æœ‰æ¨¡å—åŠå…¶é…ç½®
        for llm_name, config in self.config.get("LLM", {}).items():
            # æ£€æŸ¥é…ç½®çš„æœ‰æ•ˆæ€§
            if llm_name == "CozeLLM":
                # æ£€æŸ¥ bot_id å’Œ user_id æ˜¯å¦åŒ…å«å ä½ç¬¦
                if any(x in config.get("bot_id", "") for x in ["ä½ çš„"]) \
                        or any(x in config.get("user_id", "") for x in ["ä½ çš„"]):
                    # è‹¥åŒ…å«å ä½ç¬¦ï¼Œæ‰“å°è·³è¿‡ä¿¡æ¯
                    print(f"â­ï¸  LLM {llm_name} æœªé…ç½®bot_id/user_idï¼Œå·²è·³è¿‡")
                    continue
            # æ£€æŸ¥ api_key æ˜¯å¦åŒ…å«å ä½ç¬¦
            elif "api_key" in config and any(x in config["api_key"] for x in ["ä½ çš„", "placeholder", "sk-xxx"]):
                # è‹¥åŒ…å«å ä½ç¬¦ï¼Œæ‰“å°è·³è¿‡ä¿¡æ¯
                print(f"â­ï¸  LLM {llm_name} æœªé…ç½®api_keyï¼Œå·²è·³è¿‡")
                continue

            # å¯¹äº Ollama æ¨¡å—ï¼Œå…ˆæ£€æŸ¥æœåŠ¡çŠ¶æ€
            if llm_name == "Ollama":
                # è·å– Ollama çš„ base_urlï¼Œè‹¥æœªé…ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
                base_url = config.get('base_url', 'http://localhost:11434')
                # è·å– Ollama çš„ model_name
                model_name = config.get('model_name')
                if not model_name:
                    # è‹¥æœªé…ç½® model_nameï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯å¹¶è·³è¿‡
                    print(f"ğŸš« Ollamaæœªé…ç½®model_name")
                    continue

                # å¼‚æ­¥æ£€æŸ¥ Ollama æœåŠ¡çŠ¶æ€ï¼Œè‹¥æœåŠ¡ä¸å¯ç”¨åˆ™è·³è¿‡
                if not await self._check_ollama_service(base_url, model_name):
                    continue

            # æ‰“å°æ·»åŠ  LLM æµ‹è¯•ä»»åŠ¡çš„ä¿¡æ¯
            print(f"ğŸ“‹ æ·»åŠ LLMæµ‹è¯•ä»»åŠ¡: {llm_name}")
            # è·å–æ¨¡å—ç±»å‹ï¼Œè‹¥æœªé…ç½®åˆ™ä½¿ç”¨æ¨¡å—åç§°
            module_type = config.get('type', llm_name)
            # åˆ›å»º LLM å®ä¾‹
            llm = create_llm_instance(module_type, config)

            # ä¸ºæ¯ä¸ªæµ‹è¯•å¥å­åˆ›å»ºç‹¬ç«‹çš„æµ‹è¯•ä»»åŠ¡
            for sentence in self.test_sentences:
                # å¯¹å¥å­è¿›è¡Œç¼–ç å’Œè§£ç ï¼Œç¡®ä¿ç¼–ç æ ¼å¼ä¸º utf-8
                sentence = sentence.encode('utf-8').decode('utf-8')
                # å°†æµ‹è¯•ä»»åŠ¡æ·»åŠ åˆ° all_tasks åˆ—è¡¨ä¸­
                all_tasks.append(self._test_single_sentence(llm_name, llm, sentence))

        # å¤„ç†TTSæµ‹è¯•ä»»åŠ¡
        # éå†é…ç½®ä¸­ TTS éƒ¨åˆ†çš„æ‰€æœ‰æ¨¡å—åŠå…¶é…ç½®
        for tts_name, config in self.config.get("TTS", {}).items():
            # å®šä¹‰éœ€è¦æ£€æŸ¥çš„ä»¤ç‰Œå­—æ®µ
            token_fields = ["access_token", "api_key", "token"]
            # æ£€æŸ¥ä»¤ç‰Œå­—æ®µæ˜¯å¦åŒ…å«å ä½ç¬¦
            if any(field in config and any(x in config[field] for x in ["ä½ çš„", "placeholder"]) for field in
                token_fields):
                # è‹¥åŒ…å«å ä½ç¬¦ï¼Œæ‰“å°è·³è¿‡ä¿¡æ¯
                print(f"â­ï¸  TTS {tts_name} æœªé…ç½®access_token/api_keyï¼Œå·²è·³è¿‡")
                continue
            # æ‰“å°æ·»åŠ  TTS æµ‹è¯•ä»»åŠ¡çš„ä¿¡æ¯
            print(f"ğŸµ æ·»åŠ TTSæµ‹è¯•ä»»åŠ¡: {tts_name}")
            # å°† TTS æµ‹è¯•ä»»åŠ¡æ·»åŠ åˆ° all_tasks åˆ—è¡¨ä¸­
            all_tasks.append(self._test_tts(tts_name, config))

        # æ‰“å°æ‰¾åˆ°çš„å¯ç”¨ LLM æ¨¡å—æ•°é‡
        print(
            f"\nâœ… æ‰¾åˆ° {len([t for t in all_tasks if 'test_single_sentence' in str(t)]) / len(self.test_sentences):.0f} ä¸ªå¯ç”¨LLMæ¨¡å—")
        # æ‰“å°æ‰¾åˆ°çš„å¯ç”¨ TTS æ¨¡å—æ•°é‡
        print(f"âœ… æ‰¾åˆ° {len([t for t in all_tasks if '_test_tts' in str(t)])} ä¸ªå¯ç”¨TTSæ¨¡å—")
        # æ‰“å°æç¤ºä¿¡æ¯ï¼Œè¡¨æ˜å¼€å§‹å¹¶å‘æµ‹è¯•æ‰€æœ‰æ¨¡å—
        print("\nâ³ å¼€å§‹å¹¶å‘æµ‹è¯•æ‰€æœ‰æ¨¡å—...\n")

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æµ‹è¯•ä»»åŠ¡ï¼Œå¹¶è·å–ç»“æœ
        all_results = await asyncio.gather(*all_tasks, return_exceptions=True)

        # å¤„ç†LLMç»“æœ
        # åˆ›å»ºä¸€ä¸ªç©ºå­—å…¸ï¼Œç”¨äºå­˜å‚¨ LLM æµ‹è¯•ç»“æœ
        llm_results = {}
        # éå†æ‰€æœ‰æµ‹è¯•ç»“æœï¼Œç­›é€‰å‡º LLM ç±»å‹çš„ç»“æœ
        for result in [r for r in all_results if r and isinstance(r, dict) and r.get("type") == "llm"]:
            # è·å– LLM æ¨¡å—åç§°
            llm_name = result["name"]
            if llm_name not in llm_results:
                # è‹¥è¯¥ LLM æ¨¡å—ç»“æœæœªåœ¨ llm_results ä¸­ï¼Œåˆå§‹åŒ–å…¶ç»“æœ
                llm_results[llm_name] = {
                    "name": llm_name,
                    "type": "llm",
                    "first_token_times": [],
                    "response_times": [],
                    "errors": 0
                }
            # å°†è¯¥ LLM æ¨¡å—çš„é¦–æ¬¡ä»¤ç‰Œæ—¶é—´æ·»åŠ åˆ°å¯¹åº”çš„åˆ—è¡¨ä¸­
            llm_results[llm_name]["first_token_times"].append(result["first_token_time"])
            # å°†è¯¥ LLM æ¨¡å—çš„å“åº”æ—¶é—´æ·»åŠ åˆ°å¯¹åº”çš„åˆ—è¡¨ä¸­
            llm_results[llm_name]["response_times"].append(result["response_time"])

        # è®¡ç®—LLMå¹³å‡å€¼å’Œæ ‡å‡†å·®
        # éå† llm_results ä¸­çš„æ‰€æœ‰ LLM æ¨¡å—ç»“æœ
        for llm_name, data in llm_results.items():
            # æ£€æŸ¥è¯¥ LLM æ¨¡å—çš„é¦–æ¬¡ä»¤ç‰Œæ—¶é—´æ•°é‡æ˜¯å¦è¾¾åˆ°æµ‹è¯•å¥å­æ•°é‡çš„ä¸€åŠä»¥ä¸Š
            if len(data["first_token_times"]) >= len(self.test_sentences) * 0.5:
                # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
                avg_response = sum(data["response_times"]) / len(data["response_times"])
                # è®¡ç®—å¹³å‡é¦–æ¬¡ä»¤ç‰Œæ—¶é—´
                avg_first_token = sum(data["first_token_times"]) / len(data["first_token_times"])
                # è®¡ç®—é¦–æ¬¡ä»¤ç‰Œæ—¶é—´çš„æ ‡å‡†å·®
                std_first_token = statistics.stdev(data["first_token_times"]) if len(
                    data["first_token_times"]) > 1 else 0
                # è®¡ç®—å“åº”æ—¶é—´çš„æ ‡å‡†å·®
                std_response = statistics.stdev(data["response_times"]) if len(data["response_times"]) > 1 else 0
                # å°†è®¡ç®—ç»“æœå­˜å‚¨åˆ° self.results ä¸­
                self.results["llm"][llm_name] = {
                    "name": llm_name,
                    "type": "llm",
                    "avg_response": avg_response,
                    "avg_first_token": avg_first_token,
                    "std_first_token": std_first_token,
                    "std_response": std_response,
                    "errors": 0
                }

        # å¤„ç†TTSç»“æœ
        # éå†æ‰€æœ‰æµ‹è¯•ç»“æœï¼Œç­›é€‰å‡º TTS ç±»å‹ä¸”æ— é”™è¯¯çš„ç»“æœ
        for result in [r for r in all_results if r and isinstance(r, dict) and r.get("type") == "tts"]:
            if result["errors"] == 0:
                # å°†æ— é”™è¯¯çš„ TTS ç»“æœå­˜å‚¨åˆ° self.results ä¸­
                self.results["tts"][result["name"]] = result

        # ç”Ÿæˆç»„åˆå»ºè®®å¹¶æ‰“å°ç»“æœ
        # æ‰“å°æç¤ºä¿¡æ¯ï¼Œè¡¨æ˜å¼€å§‹ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        print("\nğŸ“Š ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
        # ç”Ÿæˆç»„åˆå»ºè®®
        self._generate_combinations()
        # æ‰“å°æµ‹è¯•ç»“æœ
        self._print_results()


async def main():
    # åˆ›å»ºä¸€ä¸ª AsyncPerformanceTester ç±»çš„å®ä¾‹
    # AsyncPerformanceTester ç±»åº”è¯¥æ˜¯ç”¨äºè¿›è¡Œå¼‚æ­¥æ€§èƒ½æµ‹è¯•çš„ç±»ï¼Œä¸è¿‡ä»£ç é‡Œæœªç»™å‡ºå…¶å®šä¹‰
    tester = AsyncPerformanceTester()
    # è°ƒç”¨ tester å¯¹è±¡çš„ run æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åº”è¯¥æ˜¯ä¸€ä¸ªå¼‚æ­¥æ–¹æ³•ï¼Œç”¨äºæ‰§è¡Œæ€§èƒ½æµ‹è¯•æ“ä½œ
    # await å…³é”®å­—ç”¨äºç­‰å¾…è¯¥å¼‚æ­¥æ–¹æ³•æ‰§è¡Œå®Œæˆ
    await tester.run()

# å½“è¯¥è„šæœ¬ä½œä¸ºä¸»ç¨‹åºè¿è¡Œæ—¶æ‰§è¡Œä»¥ä¸‹ä»£ç 
if __name__ == "__main__":
    # ä½¿ç”¨ asyncio.run å‡½æ•°æ¥è¿è¡Œå¼‚æ­¥çš„ main å‡½æ•°
    # asyncio.run å‡½æ•°ä¼šè‡ªåŠ¨åˆ›å»ºå¹¶ç®¡ç†äº‹ä»¶å¾ªç¯ï¼Œç¡®ä¿å¼‚æ­¥ä»£ç èƒ½å¤Ÿæ­£ç¡®æ‰§è¡Œ
    asyncio.run(main())